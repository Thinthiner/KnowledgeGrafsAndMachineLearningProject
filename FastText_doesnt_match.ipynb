{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "from gensim.models.fasttext import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\stine amtoft nielsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `load_fasttext_format` (use load_facebook_vectors (to use pretrained embeddings) or load_facebook_model (to continue training with the loaded full model, more RAM) instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# It takes 5 minuttes to load\n",
    "#model = FastText.load_fasttext_format('cc.en.300.bin')     # English\n",
    "model = FastText.load_fasttext_format('cc.da.300.bin')      # Dansih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"Finn_data_dansk_new.txt\",delimiter = \",\")\n",
    "#data = pd.read_csv(\"four_words_english_double.csv\",delimiter = \",\")\n",
    "\n",
    "Test_data = []\n",
    "for i in range(len(data)):\n",
    "    Test_data.append([str(data['word1'][i]),str(data['word2'][i]),str(data['word3'][i]),str(data['word4'][i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bil', 'cykel', 'tog', 'vind'] = tog\n",
      "['Lars Løkke Rasmussen', 'Poul Nyrup Rasmussen', 'Anders Fogh Rasmussen', 'Peter Schmeichel'] = Anders Fogh Rasmussen\n",
      "['Caroline Wozniacki', 'Steffi Graf', 'Serena Williams', 'Monaco'] = Serena Williams\n",
      "['Pia', 'Lone', 'Marianne', 'Ole'] = Pia\n",
      "['ishockey', 'skiløb', 'skihop', 'fodbold'] = skihop\n",
      "['gå', 'løbe', 'kravle', 'sidde'] = gå\n",
      "['Kattegat', 'Øresund', 'Alssund', 'Sjælland'] = Alssund\n",
      "['hoppende', 'dansende', 'løbende', 'døende'] = løbende\n",
      "['gange', 'dividere', 'lægge sammen', 'vandrer'] = lægge sammen\n",
      "['mener', 'tror', 'ved', 'går'] = ved\n",
      "['fire minutter', 'tre timer', 'en uge', 'to piger'] = tre timer\n",
      "['anmeldelse', 'politi', 'forbrydelse', 'kaffe'] = anmeldelse\n",
      "['tres', '60', 'LX', '3'] = tres\n",
      "['1864', '1807', '1940', '1909'] = 1807\n",
      "['dør', 'kradser af', 'udånder', 'åbner'] = kradser af\n",
      "['og', 'samt', 'endvidere', 'sin'] = og\n",
      "['stod og råbte', 'lå og sov', 'sad og så', 'mand og kvinde'] = stod og råbte\n",
      "\n",
      "Number of correct classified: 83\n",
      "Number of incorrect classified: 17\n",
      "\n",
      "Accuracy: 83.00%\n"
     ]
    }
   ],
   "source": [
    "Class_correct = 0\n",
    "Class_fail = 0\n",
    "Wrong_words_4 = []    \n",
    "    \n",
    "for i in range(len(Test_data)):\n",
    "    #Doesnt_match = model.wv.doesnt_match((\"{0} {1} {2} {3}\".format(Test_data[i][0], Test_data[i][1], Test_data[i][2], Test_data[i][3])).split())\n",
    "    Doesnt_match = model.wv.doesnt_match(Test_data[i])\n",
    "    \n",
    "    \n",
    "    if (Doesnt_match == Test_data[i][3]):\n",
    "        Class_correct += 1\n",
    "    else:\n",
    "        Class_fail += 1\n",
    "        print([Test_data[i][0], Test_data[i][1], Test_data[i][2], Test_data[i][3]], '=', Doesnt_match)\n",
    "        Wrong_words_4.append([Test_data[i][0], Test_data[i][1], Test_data[i][2], Test_data[i][3]])\n",
    "        \n",
    "print('')\n",
    "print('Number of correct classified:', Class_correct)\n",
    "print('Number of incorrect classified:', Class_fail)\n",
    "print()\n",
    "print('Accuracy: %.2f%%' %(Class_correct/(Class_correct+Class_fail)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\stine amtoft nielsen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\gensim\\models\\keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    }
   ],
   "source": [
    "Doesnt_match = model.wv.doesnt_match(Test_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vask\n"
     ]
    }
   ],
   "source": [
    "print(Doesnt_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kanal', 'program', 'udsendelse', 'vask']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "model.wv.doesnt_match([Test_data[i][0], Test_data[i][1], Test_data[i][2], Test_data[i][3]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
